{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f461474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5529559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 3381928\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('./cnus.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834d208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all non-printable characters\n",
    "file = ''.join(list(filter((lambda x: x in all_chars), file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a371b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 3381831\n"
     ]
    }
   ],
   "source": [
    "file_len = len(file)\n",
    "print('Length of file: {}'.format(file_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1cae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Sherlock dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to one-hot tensor.\n",
    "def seq_to_onehot(seq):\n",
    "    tensor = torch.zeros(len(seq), 1, n_chars) \n",
    "    # Shape of the tensor:\n",
    "    #     (sequence length, batch size, classes)\n",
    "    # Here we use batch size = 1 and classes = number of unique characters.\n",
    "    for t, char in enumerate(seq):\n",
    "        index = all_chars.index(char)\n",
    "        tensor[t][0][index] = 1\n",
    "    return tensor\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), 1)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char)\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_onehot(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]).long() # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22852b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b888a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, activation='RNN'):\n",
    "        # Initialization.\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size  = n_chars   # Input size: Number of unique chars.\n",
    "        self.hidden_size = 100       # Hidden size: 100.\n",
    "        self.output_size = n_chars   # Output size: Number of unique chars.\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        if activation == 'RNN':\n",
    "            self.activation = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "        elif activation == 'LSTM':\n",
    "            self.activation = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "        \n",
    "        self.act = activation\n",
    "            \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\" Forward function.\n",
    "              input:  One-hot input. It refers to the x_t in homework write-up.\n",
    "              hidden: Previous hidden state. It refers to the h_{t-1}.\n",
    "            Returns (output, hidden) where output refers to y_t and \n",
    "                     hidden refers to h_t.\n",
    "        \"\"\"\n",
    "        if self.act == 'RNN':\n",
    "            hidden = self.activation(input, hidden)\n",
    "            output = self.linear(hidden)\n",
    "            return output, hidden\n",
    "        else:\n",
    "            hidden, cell = self.activation(input, hidden)\n",
    "            output = self.linear(hidden)\n",
    "            return output, hidden, cell\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initial hidden state.\n",
    "        # 1 means batch size = 1.\n",
    "        return torch.zeros(1, self.hidden_size).to(device) \n",
    "    \n",
    "    def init_cell(self):\n",
    "        # Initial cell state.\n",
    "        # 1 means batch size = 1.\n",
    "        return torch.zeros(1, self.hidden_size).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e403de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step function.\n",
    "def train_step(net, opt, input, target):\n",
    "    \"\"\" Training step.\n",
    "        net:    The network instance.\n",
    "        opt:    The optimizer instance.\n",
    "        input:  Input tensor.  Shape: [seq_len, 1, n_chars].\n",
    "        target: Target tensor. Shape: [seq_len, 1].\n",
    "    \"\"\"\n",
    "    seq_len = input.shape[0]    # Get the sequence length of current input.\n",
    "    hidden = net.init_hidden()  # Initial hidden state.\n",
    "    cell = net.init_cell()      # Initial cell state\n",
    "    net.zero_grad()             # Clear the gradient.\n",
    "    loss = 0                    # Initial loss.\n",
    "    \n",
    "    if net.act == 'RNN':\n",
    "        for t in range(seq_len):    # For each one in the input sequence.\n",
    "            output, hidden = net(input[t], hidden)\n",
    "            loss += loss_func(output, target[t])\n",
    "    else:\n",
    "        for t in range(seq_len):    # For each one in the input sequence.\n",
    "            output, hidden, cell = net(input[t], (hidden, cell))\n",
    "            loss += loss_func(output, target[t])\n",
    "\n",
    "    loss.backward()             # Backward. \n",
    "    opt.step()                  # Update the weights.\n",
    "\n",
    "    return loss / seq_len       # Return the average loss w.r.t sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba76d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation step function.\n",
    "def eval_step(net, init_seq='W', predicted_len=100):\n",
    "    # Initialize the hidden state, input and the predicted sequence.\n",
    "    hidden        = net.init_hidden()\n",
    "    cell          = net.init_cell()\n",
    "    init_input    = seq_to_onehot(init_seq).to(device)\n",
    "    predicted_seq = init_seq\n",
    "\n",
    "    # If input net is RNN\n",
    "    if net.act == 'RNN':\n",
    "        # Use initial string to \"build up\" hidden state.\n",
    "        for t in range(len(init_seq) - 1):\n",
    "            output, hidden = net(init_input[t], hidden)\n",
    "        # Set current input as the last character of the initial string.\n",
    "        input = init_input[-1]\n",
    "        \n",
    "        # Predict more characters after the initial string.\n",
    "        for t in range(predicted_len):\n",
    "            # Get the current output and hidden state.\n",
    "            output, hidden = net(input, hidden)\n",
    "        \n",
    "            # Sample from the output as a multinomial distribution.\n",
    "            predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "        \n",
    "            # Add predicted character to the sequence and use it as next input.\n",
    "            predicted_char  = all_chars[predicted_index]\n",
    "            predicted_seq  += predicted_char\n",
    "        \n",
    "            # Use the predicted character to generate the input of next round.\n",
    "            input = seq_to_onehot(predicted_char)[0].to(device)\n",
    "    \n",
    "    # If input net is LSTM       \n",
    "    else:\n",
    "        # Use initial string to \"build up\" hidden state.\n",
    "        for t in range(len(init_seq) - 1):\n",
    "            output, hidden, cell = net(init_input[t], (hidden, cell))\n",
    "        # Set current input as the last character of the initial string.\n",
    "        input = init_input[-1]\n",
    "        \n",
    "        # Predict more characters after the initial string.\n",
    "        for t in range(predicted_len):\n",
    "            # Get the current output and hidden state.\n",
    "            output, hidden, cell = net(input, (hidden, cell))\n",
    "        \n",
    "            # Sample from the output as a multinomial distribution.\n",
    "            predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "        \n",
    "            # Add predicted character to the sequence and use it as next input.\n",
    "            predicted_char  = all_chars[predicted_index]\n",
    "            predicted_seq  += predicted_char\n",
    "        \n",
    "            # Use the predicted character to generate the input of next round.\n",
    "            input = seq_to_onehot(predicted_char)[0].to(device)\n",
    "\n",
    "    return predicted_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30557df9",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d66f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform n_trials each for standard RNN and LSTM.\n",
    "\n",
    "n_trials    = 3      # Number of trials per model\n",
    "iters       = 20000  # Number of training iterations per trial.\n",
    "print_iters = 100    # Number of iterations for each log printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_trial:0, iter:99/20000 loss:3.0149088311195373\n",
      "generated sequence: WM .yotor ahmmro  heeaxig iT hotfim y'ers weorsl  othlry   e rkrn a a led iunoot dt  ose   s , p Im d\n",
      "\n",
      "rnn_trial:0, iter:199/20000 loss:2.5957364106178282\n",
      "generated sequence: Wvuedclis  tomerroty ts mefhintyuler cesont\"ey dtknde?disdit  he houvkr, har Ting in.ore\n",
      " k\n",
      " monomeon\n",
      "\n",
      "rnn_trial:0, iter:299/20000 loss:2.4143584609031676\n",
      "generated sequence: Waveetraspeast to\n",
      "\n",
      "     thep,\n",
      "a   thacI bandis pmons the sas-ofpaseteYind beds soind in. the pudy..I\n",
      "\n",
      "\n",
      "rnn_trial:0, iter:399/20000 loss:2.2768567776679993\n",
      "generated sequence: Woon,\n",
      "     \"\n",
      "\n",
      "     \"Af the hacint te is Ire. at iad the chalk is is is ge'io, ing min? t\n",
      "      Bad \"W\n",
      "\n",
      "rnn_trial:0, iter:499/20000 loss:2.1708909237384795\n",
      "generated sequence: Wend ag heot ro fintre\n",
      "     bre pod anosh-\n",
      "\n",
      "     Lupnsoilure\n",
      "     nicin or\n",
      "     prerlen.\n",
      "\n",
      "      Whanp\n",
      "\n",
      "rnn_trial:0, iter:599/20000 loss:2.106221311092377\n",
      "generated sequence: Whed ssaiins of\n",
      "     the save brobreHnvert cucps siren simy\n",
      "     anice in I kor?\"I\n",
      "     menons a ditt\n",
      "\n",
      "rnn_trial:0, iter:699/20000 loss:2.0702593433856964\n",
      "generated sequence: Wertiel to ting beoud nt an curt, Haltreen .\"Noken Hot han lere tamedara. There ther\n",
      "     wot wOko an\n",
      "\n",
      "rnn_trial:0, iter:799/20000 loss:2.0683761715888975\n",
      "generated sequence: Weneted thy cally fere!\"Nedt foreal andy way thit thould so laydy ane\n",
      "     flle\n",
      "     \"At by anet\n",
      "    \n",
      "\n",
      "rnn_trial:0, iter:899/20000 loss:2.0049230539798737\n",
      "generated sequence: Wid pledreat but the retrel wolt willstem lozttre wit ug cavenedusg him a nor whid. Hou that hould, w\n",
      "\n",
      "rnn_trial:0, iter:999/20000 loss:2.0176544678211212\n",
      "generated sequence: Were pohtare himsich, Wain uitsousingte the\n",
      "     the attat a most thatrablon\n",
      "     thack we I hivk co \n",
      "\n",
      "rnn_trial:0, iter:1099/20000 loss:1.959001717567444\n",
      "generated sequence: We make bibicuid in Lofit at licaly folt iedyou, as at stle had selve. Jou ro, you mo get it come an \n",
      "\n",
      "rnn_trial:0, iter:1199/20000 loss:1.969046756029129\n",
      "generated sequence: Whe\n",
      "     adsed Mr.\n",
      "     wiid you hiver Hereped the prilw. It is thit ofs dod hondird I cryof\n",
      "\n",
      "     \"'\n",
      "\n",
      "rnn_trial:0, iter:1299/20000 loss:1.9615035712718965\n",
      "generated sequence: Wewtia thas Bean they worp wiy tho thaich\n",
      "\n",
      "     \"Cad, the coud juan ol stear eey aven here of ane te \n",
      "\n",
      "rnn_trial:0, iter:1399/20000 loss:1.9846488201618195\n",
      "generated sequence: Wat I lock no men'spppant mand.\"\n",
      "\n",
      "     \"Ant itherticimenicily Lasedpeared rethime afpi't\n",
      "     stcater\n",
      "\n",
      "rnn_trial:0, iter:1499/20000 loss:1.953875072002411\n",
      "generated sequence: Wisusims to houlo me Tot weoredytenlled by the con\n",
      "\n",
      "     he pronds netginint gie--s a ondered we\n",
      "    \n",
      "\n",
      "rnn_trial:0, iter:1599/20000 loss:1.9062133538722992\n",
      "generated sequence: Wing is mard. Ner, mutcly a   I hourd, and. I the chime the f the came of man all thlis the backev th\n",
      "\n",
      "rnn_trial:0, iter:1699/20000 loss:1.8860350131988526\n",
      "generated sequence: Wh if ob lly it feld the fJaned that I how len icele me ous and cewo th thee, seables apleded up nagl\n",
      "\n",
      "rnn_trial:0, iter:1799/20000 loss:1.8735176956653594\n",
      "generated sequence: Wenent.\n",
      "\n",
      "     \"Dhe fin, a, witilingen acveride, pe to me\n",
      "     threse betorises. Winct ditmaline then \n",
      "\n",
      "rnn_trial:0, iter:1899/20000 loss:1.9080639243125916\n",
      "generated sequence: Wereed had.\n",
      "\n",
      "     \"Itwesose. Thustont to fucl thatatentathy Orishing hades muththore intanctedins to \n",
      "\n",
      "rnn_trial:0, iter:1999/20000 loss:1.909208607673645\n",
      "generated sequence: Wele seaccrots, wextuley heot mar, wimormes at thar boids that whis, wo brime ttangaled helse a bling\n",
      "\n",
      "rnn_trial:0, iter:2099/20000 loss:1.8526786422729493\n",
      "generated sequence: Whiccere, theme rroary\n",
      "     my part.\"\n",
      "\n",
      "     \"Thenes you ur. At frimank manst gow and he was of come. \n",
      "\n",
      "rnn_trial:0, iter:2199/20000 loss:1.8658225858211517\n",
      "generated sequence: Warked, as imwepigion of the\n",
      "     burncened obrecemviit, but tiinged the stret whel digenquen shourd \n",
      "\n",
      "rnn_trial:0, iter:2299/20000 loss:1.8472028803825378\n",
      "generated sequence: Ward\n",
      "     anots an oul overushing ot the tirabsher ho. Laton\n",
      "     imong is\n",
      "     the chispunct,       \n",
      "\n",
      "rnn_trial:0, iter:2399/20000 loss:1.871586216688156\n",
      "generated sequence: We\n",
      "     has, and we\n",
      "     rewill you moresst ot of the rrasply the\n",
      "     within\n",
      "     soid it\n",
      "     layce\n",
      "\n",
      "rnn_trial:0, iter:2499/20000 loss:1.8745327723026275\n",
      "generated sequence: Wet nir late torlly to the rakneragor, bor me well. Weld inderdable with room.\"\n",
      "\n",
      "     inat roomekne. \n",
      "\n",
      "rnn_trial:0, iter:2599/20000 loss:1.8783632457256316\n",
      "generated sequence: We lence\n",
      "     EtGol some, frices.\n",
      "\n",
      "\n",
      "  t tar thore I'tlen Streftiad,\" n 20 He conting wesl, thowing wi\n",
      "\n",
      "rnn_trial:0, iter:2699/20000 loss:1.8290803027153015\n",
      "generated sequence: Wo caireEmalm the moEs.\n",
      "\n",
      "     \"wis mind-m said in to courtarnaring his pot howners.\n",
      "\n",
      "     \"'shing a b\n",
      "\n",
      "rnn_trial:0, iter:2799/20000 loss:1.824234219789505\n",
      "generated sequence: We an he sow thow. It with she sar, and are you us.\"\n",
      "\n",
      "     Wusherltu-he caresses of to by senet. Our \n",
      "\n",
      "rnn_trial:0, iter:2899/20000 loss:1.825722770690918\n",
      "generated sequence: Whor led chee ointed find a sare\n",
      "     Shink have the recore chied he, ar Cimisal th? \"I raron droon-o\n",
      "\n",
      "rnn_trial:0, iter:2999/20000 loss:1.80328427195549\n",
      "generated sequence: Wes aboulenth the conttay bear thes wath yecrimenk suaven sloite the pess. I, grems lithy the costare\n",
      "\n",
      "rnn_trial:0, iter:3099/20000 loss:1.8093458211421967\n",
      "generated sequence: Whow. Even up sown.\"\n",
      "\n",
      "     Aurivery pricoid of oncor.\n",
      "     At in noge the said-bootnof, and Dout you \n",
      "\n",
      "rnn_trial:0, iter:3199/20000 loss:1.8684807562828063\n",
      "generated sequence: Wark to know I could\n",
      "     about do pur. And.\"\n",
      "\n",
      "    was lich of whe agh mecentaer for that with ary pi\n",
      "\n",
      "rnn_trial:0, iter:3299/20000 loss:1.8153811275959015\n",
      "generated sequence: We, Dade patser.\"\n",
      "\n",
      "     \"Whould cortero, was tale be poking wiok to sisted you, is werh whan samed st\n",
      "\n",
      "rnn_trial:0, iter:3399/20000 loss:1.8102381348609924\n",
      "generated sequence: Wesive; is to the\n",
      "     I and to have I way, had souad then singuararderainesteryon, her alled but har\n",
      "\n",
      "rnn_trial:0, iter:3499/20000 loss:1.8234037733078003\n",
      "generated sequence: Waye chant as to my fenetes for with to the deabats sithin acton with the lanted this a she heart we \n",
      "\n",
      "rnn_trial:0, iter:3599/20000 loss:1.7877557361125946\n",
      "generated sequence: Whernol,\" I lack Half. That days dother a rtatine. my blon of a crntens.\"\n",
      "\n",
      "     \"That ald obld.\" I's \n",
      "\n",
      "rnn_trial:0, iter:3699/20000 loss:1.7775262606143951\n",
      "generated sequence: Whte.\n",
      "     \"I had\n",
      "     botsed ackereyore,\" stripsh to Buttlatyad we who lepwor enenderstalp wE lought\n",
      "\n",
      "rnn_trial:0, iter:3799/20000 loss:1.8005203354358672\n",
      "generated sequence: War hhis est gother my frewnosains my sam, weres he\n",
      "     sfied?\" Hared fin hil vorf, do late wring of\n",
      "\n",
      "rnn_trial:0, iter:3899/20000 loss:1.7989250493049622\n",
      "generated sequence: Wated tore\n",
      "     deenine.\"\n",
      "\n",
      "     \"'xElkerer soched\n",
      "     with a tarfmented to me mait me mut ho like it\n",
      "\n",
      "rnn_trial:0, iter:3999/20000 loss:1.7746829187870026\n",
      "generated sequence: With Hee, and this quess, and a dract an the adatured of you the  and linion a has have havisellad. I\n",
      "\n",
      "rnn_trial:0, iter:4099/20000 loss:1.7691417491436006\n",
      "generated sequence: Wh the manty which I had room they and a gaepef mign eady in sim; had bike alsed. You work Mr. \"Therr\n",
      "\n",
      "rnn_trial:0, iter:4199/20000 loss:1.7838838982582093\n",
      "generated sequence: Will. I thath abrew. It the\n",
      "     do your whow defor.\n",
      "\n",
      "     \"Whes ncataels\n",
      "     as\n",
      "     asper expbo gr\n",
      "\n",
      "rnn_trial:0, iter:4299/20000 loss:1.7643572759628297\n",
      "generated sequence: Will\n",
      "     \" shorrearath tistofly rubure, in were dearing capemelicged my prrerommedseated me offectig\n",
      "\n",
      "rnn_trial:0, iter:4399/20000 loss:1.7802097880840302\n",
      "generated sequence: Whter\n",
      "     out formes there yound om your edtersion my dewive I cagkn who suplious to?'M\n",
      "\n",
      "     Shill \n",
      "\n",
      "rnn_trial:0, iter:4499/20000 loss:1.774585165977478\n",
      "generated sequence: Werhtaur, and we the evehing which me hyved was unders. If at of I reand therlecter uppreworsturifea \n",
      "\n",
      "rnn_trial:0, iter:4599/20000 loss:1.8087335705757142\n",
      "generated sequence: Whing a fatimed that you somehto sect do have agook Sale lister your thour it a fowayy of they mindom\n",
      "\n",
      "rnn_trial:0, iter:4699/20000 loss:1.7553772306442261\n",
      "generated sequence: Woncecun with oth seved thrud. For whelolver of\n",
      "     hour oftessed Gous chatatiens at a morted of the\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_trial:0, iter:4799/20000 loss:1.759950270652771\n",
      "generated sequence: Weys. I sury in aghen ate usele.\n",
      "\n",
      "     \"But o to tter ther a sharmy mes, sho or our deay. He look sti\n",
      "\n",
      "rnn_trial:0, iter:4899/20000 loss:1.7770441353321076\n",
      "generated sequence: Will\n",
      "     Cloident wand fure cone, he bent withwore! Wold, from if youlloct, rethe what eevers where \n",
      "\n",
      "rnn_trial:0, iter:4999/20000 loss:1.7556602215766908\n",
      "generated sequence: Well whath herraidase, anded. I was sobly-sowarible.\n",
      "\n",
      " \n",
      "     Vustestan. It ouls. If you vast had cwas\n",
      "\n",
      "rnn_trial:0, iter:5099/20000 loss:1.7402511966228484\n",
      "generated sequence: We bugan'ves on the was enou. I froppee mine. EA as no dinve outtalm supsiaded us no\n",
      "     rome makfor\n",
      "\n",
      "rnn_trial:0, iter:5199/20000 loss:1.7512087976932527\n",
      "generated sequence: Wiod I is as as eave he was inter befere's upran. The sars\n",
      "     shave I\n",
      "    .\"\n",
      "\n",
      "     \"I and yot\n",
      "     \n",
      "\n",
      "rnn_trial:0, iter:5299/20000 loss:1.7385446393489838\n",
      "generated sequence: Whpor durkith insteannay he orling and wish and pactanded the say. It was\n",
      "     shoucceabl fore uptoon\n",
      "\n",
      "rnn_trial:0, iter:5399/20000 loss:1.7267262077331542\n",
      "generated sequence: Welf, trabseds of the chadned it,\n",
      "     bike upon the ! the bo upon\n",
      "     to dimeted\n",
      "     dreal thoul a\n",
      "\n",
      "rnn_trial:0, iter:5499/20000 loss:1.750999082326889\n",
      "generated sequence: Well, and wat anveg. Then the sidit it. 'Alder in\n",
      "     town\n",
      "     diggion\n",
      "     They meen orpturhso tha\n",
      "\n",
      "rnn_trial:0, iter:5599/20000 loss:1.715707963705063\n",
      "generated sequence: Well! Bock fouth medtlte, work I was Gad k'll streced to\n",
      "     no the Gilus wind of crautry it was abi\n",
      "\n",
      "rnn_trial:0, iter:5699/20000 loss:1.7301955580711366\n",
      "generated sequence: Whoted\n",
      "     bernecty worever noverorver of\n",
      "     Bame to hurlf the\n",
      "     niwing any Hat, fanting then o\n",
      "\n",
      "rnn_trial:0, iter:5799/20000 loss:1.7072453331947326\n",
      "generated sequence: Wethin but as\n",
      "     chisiggor that all she famer any\n",
      "     no danncelgas to moredide into horfieticinge\n",
      "\n",
      "rnn_trial:0, iter:5899/20000 loss:1.7466988372802734\n",
      "generated sequence: What I as Dlocker, seat this? I wag. Cibery not it that then?\"\n",
      "\n",
      "     'Iss would you his mbatt. I shim\n",
      "\n",
      "rnn_trial:0, iter:5999/20000 loss:1.77368701338768\n",
      "generated sequence: Wirl, shallow, our to his fichind which\n",
      "     withorg,'\n",
      "     way, onlime Mo whith the same\n",
      "     on a w\n",
      "\n",
      "rnn_trial:0, iter:6099/20000 loss:1.759277355670929\n",
      "generated sequence: We my\n",
      "\n",
      "     \"This meden suglozed that yit this by the Gon which conme, mile ccliting he concactame.\n",
      " \n",
      "\n",
      "rnn_trial:0, iter:6199/20000 loss:1.733223431110382\n",
      "generated sequence: We ofterger that\n",
      "     which him cup to till that it word pasatinizes which showid vecg and the fasion\n",
      "\n",
      "rnn_trial:0, iter:6299/20000 loss:1.7142305624485017\n",
      "generated sequence: Were!orranczusned iningurnalkid. Thraugsion, to sen's all\n",
      "     of have she there\n",
      "     very anle who c\n",
      "\n",
      "rnn_trial:0, iter:6399/20000 loss:1.730016667842865\n",
      "generated sequence: Way frone intussifninustoyer has intern pretinetwrouened upon, sidzed, ander and handrrutainessiee, h\n",
      "\n",
      "rnn_trial:0, iter:6499/20000 loss:1.7428408205509185\n",
      "generated sequence: Wat and oxcey buturisndey b own's aplicy recomar in the qyame found mo the know her; aPd shad bearry \n",
      "\n",
      "rnn_trial:0, iter:6599/20000 loss:1.7390832948684691\n",
      "generated sequence: We yefl\n",
      "     his loomes\n",
      "     ho.\n",
      "\n",
      "     \"A may, and the peacesoonskindvis. They reguytt had\n",
      "     knacr\n",
      "\n",
      "rnn_trial:0, iter:6699/20000 loss:1.7032665812969208\n",
      "generated sequence: Which tering sur will dearttge. \"Iuch was findtaw and twe\n",
      "     this with shear\n",
      "     one on that he mo\n",
      "\n",
      "rnn_trial:0, iter:6799/20000 loss:1.7177354407310486\n",
      "generated sequence: Wand tore cal tobou ussered.\"\n",
      "\n",
      "     \"head cake ans.\n",
      "     \"Ioced giisn  Southtain on ead comes to that\n",
      "\n",
      "rnn_trial:0, iter:6899/20000 loss:1.7408829200267792\n",
      "generated sequence: We in anses tibics shaul\n",
      "     pered so fiftlere as ith, it Mr membrish of the emar. By got and see wh\n",
      "\n",
      "rnn_trial:0, iter:6999/20000 loss:1.74463117480278\n",
      "generated sequence: Wht spo you thiins fittheraigh's at the\n",
      "     whice is me persaldain--it maips it! Suopheagal?'\n",
      "\n",
      "     \n",
      "\n",
      "rnn_trial:0, iter:7099/20000 loss:1.7544005525112152\n",
      "generated sequence: Was praie you! Whem. You more bewndsal,\n",
      "     to the said he fichinnal\n",
      "     pivid the pad inbout her i\n",
      "\n",
      "rnn_trial:0, iter:7199/20000 loss:1.7452481877803803\n",
      "generated sequence: What I\n",
      "     saivent the eight came no a for we chanded been the exferey. I would eave he perimemus to\n",
      "\n",
      "rnn_trial:0, iter:7299/20000 loss:1.7501349925994873\n",
      "generated sequence: We him sanding as lon, of\n",
      "     reet asincet is pasce the pasion. Doly up the in the cilicated\n",
      "     th\n",
      "\n",
      "rnn_trial:0, iter:7399/20000 loss:1.7015957641601562\n",
      "generated sequence: Weys is mescreat his housh upon the sift the suemincled me crjudive in three courhaps of the not suce\n",
      "\n",
      "rnn_trial:0, iter:7499/20000 loss:1.7499466300010682\n",
      "generated sequence: Wet atatwing\n",
      "     pess to miivizurs\n",
      "     heald, was out no lood of a way but of the scalled gurnion p\n",
      "\n",
      "rnn_trial:0, iter:7599/20000 loss:1.7124189865589141\n",
      "generated sequence: Wet\n",
      "     how?\" cets. I two went his old her. The cernty's gess bust me. I meke\n",
      "     comblest matter h\n",
      "\n",
      "rnn_trial:0, iter:7699/20000 loss:1.6859453988075257\n",
      "generated sequence: Whis, when, and bil\n",
      "     lads. Fidesed geep in an sirposs. 'Yout having an way befich mocristed befic\n",
      "\n",
      "rnn_trial:0, iter:7799/20000 loss:1.6973890686035156\n",
      "generated sequence: Well,\" saferened geresting at thout nosader, the brenge.\"\n",
      "\n",
      "     \"You om agiedtable was that I to the \n",
      "\n",
      "rnn_trial:0, iter:7899/20000 loss:1.7354402649402618\n",
      "generated sequence: Well,' shor drishitne erowh of prebsh amar time wour, Mrr.\n",
      "\n",
      "     \"We sids, you said.\"\n",
      "\n",
      "     \"EEd\n",
      "    \n",
      "\n",
      "rnn_trial:0, iter:7999/20000 loss:1.6938153111934662\n",
      "generated sequence: We op have net here,\" say nay st intely\n",
      "     Cark,\" said. \"Carred whithing nothing dianged sith the d\n",
      "\n",
      "rnn_trial:0, iter:8099/20000 loss:1.724652235507965\n",
      "generated sequence: Waln kormong evel!\" he grous,\" the wence. We have doston, we hadnly mave I saver. This this is sometm\n",
      "\n",
      "rnn_trial:0, iter:8199/20000 loss:1.7139487409591674\n",
      "generated sequence: Walk it raint to be\n",
      "     hoffer had shourh watHoves the rolth to closen\n",
      "     hadd-a trar sfaw bequar \n",
      "\n",
      "rnn_trial:0, iter:8299/20000 loss:1.7224922585487366\n",
      "generated sequence: Way breyry with curene.\" The fift be such be\n",
      "' Apps\n",
      " \n",
      "   luarioup outfered, than to man! though\" call\n",
      "\n",
      "rnn_trial:0, iter:8399/20000 loss:1.6966498339176177\n",
      "generated sequence: Wes it. He put\n",
      "     other of his so ponyed us\n",
      "     it is murn that es there was othar, but of the luo\n",
      "\n",
      "rnn_trial:0, iter:8499/20000 loss:1.6781817293167114\n",
      "generated sequence: Wat from taksidefp cont ald clear inturned which patat have for\n",
      "     till. \"With counded him eand hid\n",
      "\n",
      "rnn_trial:0, iter:8599/20000 loss:1.7151901078224183\n",
      "generated sequence: Well to Corson, I any non through pails on that but to you thought oter be tollody if have confiwed, \n",
      "\n",
      "rnn_trial:0, iter:8699/20000 loss:1.6719278049468995\n",
      "generated sequence: Well. I lite seemped the case-cate bvalling to toabed him he man of this evext surntding dil the sorn\n",
      "\n",
      "rnn_trial:0, iter:8799/20000 loss:1.6774147963523864\n",
      "generated sequence: We caWe that he have our your fake the puran foor heard; and Mrevectuieed. Ning frim,\" saiply hat me \n",
      "\n",
      "rnn_trial:0, iter:8899/20000 loss:1.7176830208301543\n",
      "generated sequence: What\n",
      "     sulpom.\n",
      "\n",
      "     \"Mr. Wake telisece its, shere at\n",
      "     Hen lester\n",
      "     meth my overy of that t\n",
      "\n",
      "rnn_trial:0, iter:8999/20000 loss:1.7193275606632232\n",
      "generated sequence: Whes Gortisdly shem the Pcasted my brows which be orted from anded is\n",
      "     such sakeaver mirdible wil\n",
      "\n",
      "rnn_trial:0, iter:9099/20000 loss:1.7476346397399902\n",
      "generated sequence: Whim themives it whole with the formine----Proas, and Morrott wiplos feilition. But it.\n",
      "     ut on th\n",
      "\n",
      "rnn_trial:0, iter:9199/20000 loss:1.7117846250534057\n",
      "generated sequence: What leady my rur staring tem I and and her qy. I sprame ally momental. And it was paued it yout deye\n",
      "\n",
      "rnn_trial:0, iter:9299/20000 loss:1.6926823794841765\n",
      "generated sequence: Wh the most in must ho. \"It fele marather without niberbal, us I canes her that they?\"\n",
      "\n",
      "     \"It was \n",
      "\n",
      "rnn_trial:0, iter:9399/20000 loss:1.6848803460597992\n",
      "generated sequence: WUys being. but stallt we\n",
      "     pounibl thoughing. The lork with oved frone, biens who upon\n",
      "     ball \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_trial:0, iter:9499/20000 loss:1.7358119678497315\n",
      "generated sequence: Way steprition con jow.\"\n",
      "\n",
      "     \"I's dole objenly who sught hads of you casting hirraghy own\n",
      "     shac\n",
      "\n",
      "rnn_trial:0, iter:9599/20000 loss:1.7003621995449065\n",
      "generated sequence: We presuntigg younatet, at\n",
      "     him, that yepruee this man up a\n",
      "     came arregnonct--,\n",
      "     not a Nu\n",
      "\n",
      "rnn_trial:0, iter:9699/20000 loss:1.6898574149608612\n",
      "generated sequence: Wens, fool of the laster a rooms heard as\n",
      "     of the angenion the\n",
      "     into Honkesorn, stapstions av\n",
      "\n",
      "rnn_trial:0, iter:9799/20000 loss:1.6957083320617676\n",
      "generated sequence: What's flayes. He every anev 'remance. Scervehhed his asked of husher.!\"I, Whom my combono\n",
      "     hill.\n",
      "\n",
      "rnn_trial:0, iter:9899/20000 loss:1.7169000101089478\n",
      "generated sequence: Wh the findon frome fill on the bloottames on must will.\"\n",
      "\n",
      "     \"What\n",
      "     Dome to we these. No at ag\n",
      "\n",
      "rnn_trial:0, iter:9999/20000 loss:1.6968615138530732\n",
      "generated sequence: When this the liff nog to, with enstinatised to-faysued.\n",
      "\n",
      "     \"Not\n",
      "     owamion as---That the mat'te\n",
      "\n",
      "rnn_trial:0, iter:10099/20000 loss:1.6881959414482117\n",
      "generated sequence: Whis is ever to By tram.\n",
      "     We strarameloobly be dear Blider, Has,\" a wear's his fCleary terkabt, s\n",
      "\n",
      "rnn_trial:0, iter:10199/20000 loss:1.7222579360008239\n",
      "generated sequence: Was only, I feich. \"It a! I feallesser. Thas, I gueber upon cleaiochs agature the chatter belong but \n",
      "\n",
      "rnn_trial:0, iter:10299/20000 loss:1.6815152966976166\n",
      "generated sequence: Welled in the errty\n",
      "     come some com which squer And up at kleen stoieponef anyel, buff,\n",
      "     place\n",
      "\n",
      "rnn_trial:0, iter:10399/20000 loss:1.6905947458744048\n",
      "generated sequence: We might my resains. OHone, ear have him. Hiller?\"\n",
      "\n",
      "     \"If lantl, and hid stridy from, awacted at a\n",
      "\n",
      "rnn_trial:0, iter:10499/20000 loss:1.7090964150428771\n",
      "generated sequence: What witled conitaked pinde.\n",
      "\n",
      "     \"Homes anst foak.\n",
      "\n",
      "     \"You seven oll bise.\"\n",
      "\n",
      "     \"Nt's to be!\"\n",
      "\n",
      "\n",
      "rnn_trial:0, iter:10599/20000 loss:1.6872874438762664\n",
      "generated sequence: Whe into\n",
      "     into knowarhat that it pousist with done! Wit bound joom.\"\n",
      "\n",
      "     \"The houng hen rever w\n",
      "\n",
      "rnn_trial:0, iter:10699/20000 loss:1.7176862812042237\n",
      "generated sequence: What in any when a scoulded me the ached you all. The have a mearnd in the awaud and that she last in\n",
      "\n",
      "rnn_trial:0, iter:10799/20000 loss:1.6750942146778107\n",
      "generated sequence: Whit year I litt it\n",
      "     there which hendimy, mine stidawallow. It is St.\n",
      "\n",
      "     \"Hooo happer at hush \n",
      "\n",
      "rnn_trial:0, iter:10899/20000 loss:1.6884151792526245\n",
      "generated sequence: Whow is a sates.\n",
      "\n",
      "     And his ids to you the strouge ever still. Anytre take taked\n",
      "     dild my\n",
      "    \n",
      "\n",
      "rnn_trial:0, iter:10999/20000 loss:1.7266773390769958\n",
      "generated sequence: Whole by nearn we kaid been we have to it imponted the fable as shoubve am, panve I wite to caser afa\n",
      "\n",
      "rnn_trial:0, iter:11099/20000 loss:1.6618831193447112\n",
      "generated sequence: What to the single havaght how. He javelnar,. Am. Hask a seuppe had hadd all Fition hallly the farthi\n",
      "\n",
      "rnn_trial:0, iter:11199/20000 loss:1.6855148959159851\n",
      "generated sequence: What refiched is it is the pasled-back. \"I was intived of his that my some the reticuriby inday out t\n",
      "\n",
      "rnn_trial:0, iter:11299/20000 loss:1.6992189538478852\n",
      "generated sequence: We supplur, by then\n",
      "     dowrve secret otMo. \"Ve moor I my?\"\n",
      "\n",
      "     \"You have alates ver upaors and ru\n",
      "\n",
      "rnn_trial:0, iter:11399/20000 loss:1.7050576305389404\n",
      "generated sequence: What wist is dome that my not the fint marred to down be.\"\n",
      "\n",
      "     It disting to the make in some raid \n",
      "\n",
      "rnn_trial:0, iter:11499/20000 loss:1.650641748905182\n",
      "generated sequence: Wedle was at it as it--Huring at inzerare\n",
      "     pamet not think and up Betherement, here in then the m\n",
      "\n",
      "rnn_trial:0, iter:11599/20000 loss:1.7006007993221284\n",
      "generated sequence: What when, senrat was prosable. No, fectien and pixaned a\n",
      "     mey. The batured as with the tream in \n",
      "\n",
      "rnn_trial:0, iter:11699/20000 loss:1.6786019241809844\n",
      "generated sequence: Whe pang a On the elt be six as the lauses his awin a queaster. It I tiard he dawning. \"It workes. No\n",
      "\n",
      "rnn_trial:0, iter:11799/20000 loss:1.658662999868393\n",
      "generated sequence: Wat of\n",
      "     eacenaret and locking\n",
      "     advioim. I shill, Miser, and no'lockled. Inow\n",
      "     ay the nabl\n",
      "\n",
      "rnn_trial:0, iter:11899/20000 loss:1.721165841817856\n",
      "generated sequence: We, advails dregamess; thought was asseisk feck fantiol, and here is ragit sknar. She coures as there\n",
      "\n",
      "rnn_trial:0, iter:11999/20000 loss:1.6726654720306398\n",
      "generated sequence: When I dands the ceresmess. I dizst comooce that he was\n",
      "     you urourning more a quesenly come. I ca\n",
      "\n",
      "rnn_trial:0, iter:12099/20000 loss:1.694157955646515\n",
      "generated sequence: What and the bleary, lost\n",
      "     the rament nocwable to the lasting, and uponacly. Fecken,\" herranuly. \n",
      "\n",
      "rnn_trial:0, iter:12199/20000 loss:1.6746530508995057\n",
      "generated sequence: We were\n",
      "     willou, and I, it,         Then as cite-liatuly, and to the flotden stient concoot-gay s\n",
      "\n",
      "rnn_trial:0, iter:12299/20000 loss:1.6803490793704987\n",
      "generated sequence: Whtlated wot' in holet mancreary for his who extate, so said I verwatners\n",
      "     stroaging\n",
      "     dement \n",
      "\n",
      "rnn_trial:0, iter:12399/20000 loss:1.6652572226524354\n",
      "generated sequence: We a blows out and elr, the neve other would cingulath from a pird.\"\n",
      "\n",
      "     Rangworef, and if sir, may\n",
      "\n",
      "rnn_trial:0, iter:12499/20000 loss:1.6992301094532012\n",
      "generated sequence: Wh my, Mor.\n",
      "\n",
      "     \"I sain\n",
      "     chee--McColsm.\n",
      "\n",
      "     The expec crest servac Falliag over in a\n",
      "     car\n",
      "\n",
      "rnn_trial:0, iter:12599/20000 loss:1.6985022914409638\n",
      "generated sequence: What would same was now casersaorf, Wask the glarce Bruntss no under-prest, sugrnt?\"\n",
      "\n",
      "     \"At the th\n",
      "\n",
      "rnn_trial:0, iter:12699/20000 loss:1.6870819878578187\n",
      "generated sequence: We mosing thunce it. Her hamo atinged\n",
      "     stoush mway\n",
      "     dreaw\n",
      "    \n",
      "     rughtand. Lethal to the i\n",
      "\n",
      "rnn_trial:0, iter:12799/20000 loss:1.6825481510162354\n",
      "generated sequence: Wh thich he decain asswer beesser oce of the aword bugur macring'f than you was at and throen defidar\n",
      "\n",
      "rnn_trial:0, iter:12899/20000 loss:1.6699367249011994\n",
      "generated sequence: What, consiile vor Lottent, Wand pormingiss, and Aguy o covearly, As firl, ther no upon sit' that ad,\n",
      "\n",
      "rnn_trial:0, iter:12999/20000 loss:1.6511950850486756\n",
      "generated sequence: When 'Theride'c streatiay tribthinulary's fruemer town which to bolsons.\"\n",
      "\n",
      "     supparbal and cams.\"\n",
      "\n",
      "\n",
      "rnn_trial:0, iter:13099/20000 loss:1.677056314945221\n",
      "generated sequence: What found eack and I shour of which\n",
      "     that he\n",
      "     bill as my do.\"\n",
      "\n",
      "     That their and and there\n",
      "\n",
      "rnn_trial:0, iter:13199/20000 loss:1.6767448329925536\n",
      "generated sequence: West, and eens triphing\n",
      "\n",
      "     \"Ifsent.\n",
      "\n",
      "     \"Hot the person.\" He seet.\n",
      "\n",
      "     But the his eyshapside.\n",
      "\n",
      "rnn_trial:0, iter:13299/20000 loss:1.6472201991081237\n",
      "generated sequence: What not I have at\n",
      "     was nats then I, exppodimagien?' had greepthes may.\"\n",
      "\n",
      "      how\n",
      "     then the\n",
      "\n",
      "rnn_trial:0, iter:13399/20000 loss:1.736448495388031\n",
      "generated sequence: We salicom of the cury ow suckey plach to tho side'.\n",
      "     When the nose behimm. The once.\n",
      "\n",
      "     \"You \n",
      "\n",
      "rnn_trial:0, iter:13499/20000 loss:1.6717833971977234\n",
      "generated sequence: Wh the heard\n",
      "     ay my them, I had to man the meald. The pot a sisty of they arrea, a tholinedlee,\" \n",
      "\n",
      "rnn_trial:0, iter:13599/20000 loss:1.728724719285965\n",
      "generated sequence: We tibstand. I lighes maserry that our hwast.\n",
      "\n",
      "     \"Ounients age. That lade on the fibleMglay ellf-e\n",
      "\n",
      "rnn_trial:0, iter:13699/20000 loss:1.676348216533661\n",
      "generated sequence: What fellogrs grads!\"\n",
      "\n",
      "     \"Um.\"\n",
      "\n",
      "     \"Call-some with the Camise of her farre hop's you he wall. Oh\n",
      "\n",
      "rnn_trial:0, iter:13799/20000 loss:1.692433089017868\n",
      "generated sequence: Why  langed,\n",
      "     and not betsimen,'I stipdimrurss himplated at? One a reason of araw otnerly yot,\n",
      "  \n",
      "\n",
      "rnn_trial:0, iter:13899/20000 loss:1.7006904196739197\n",
      "generated sequence: What is him his back dessia for the Mrom.\n",
      "\n",
      "     And in it was it cumy are some me drest tsad it weeke\n",
      "\n",
      "rnn_trial:0, iter:13999/20000 loss:1.6854758083820343\n",
      "generated sequence: We-bind with a look, you bling. I am had sently\n",
      "     to\n",
      "     higl momenrd not been frow in\n",
      "     porta\n",
      "\n",
      "rnn_trial:0, iter:14099/20000 loss:1.6584665250778199\n",
      "generated sequence: We he\n",
      "     yane which be pronpware shookne, for come in upserwees there ran upon a landed the jast, d\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_trial:0, iter:14199/20000 loss:1.6579045009613038\n",
      "generated sequence: Wet\n",
      "     and the his had not, looks, sinngghthing, was, Proth save the stpacining\n",
      "     excem in volle\n",
      "\n",
      "rnn_trial:0, iter:14299/20000 loss:1.671894680261612\n",
      "generated sequence: Wive beecters and shouvep efoullowed in my dowef urtien, to me the bound goifedured fissester. Acter \n",
      "\n",
      "rnn_trial:0, iter:14399/20000 loss:1.6748746132850647\n",
      "generated sequence: Wey. The sury, it\n",
      "     the his Cowers up, which Bepoutout old the santer the thirruss the tropperore \n",
      "\n",
      "rnn_trial:0, iter:14499/20000 loss:1.6547527194023133\n",
      "generated sequence: Whis meswers direltist litts, and that this uttern, become.\n",
      "\n",
      "     \"Not of no usent Got St. She from h\n",
      "\n",
      "rnn_trial:0, iter:14599/20000 loss:1.6410621297359467\n",
      "generated sequence: Wit, his hall was I\n",
      "     extless dyen in the moundce and I\n",
      "     purners the menes, and he wough I vat\n",
      "\n",
      "rnn_trial:0, iter:14699/20000 loss:1.636257246732712\n",
      "generated sequence: Why man, treds teuding\n",
      "     impleced had seep opent, had\n",
      "     dowzlaned it so asining straight, and t\n",
      "\n",
      "rnn_trial:0, iter:14799/20000 loss:1.6759196424484253\n",
      "generated sequence: We bedas, fo wilkers ta hesied-heep the goors when he his intasling\n",
      "     my mosching,\n",
      "     vigited on\n",
      "\n",
      "rnn_trial:0, iter:14899/20000 loss:1.6718227458000183\n",
      "generated sequence: Who seet soors. We couse so extersons he wout inlongrugss which very instarve\n",
      "     sircundly withone \n",
      "\n",
      "rnn_trial:0, iter:14999/20000 loss:1.7255996263027191\n",
      "generated sequence: Wet Sir und asar\n",
      "     \"In e's. It is a cunk a wafe yeatso almonacat peive's offlicary, it them fear h\n",
      "\n",
      "rnn_trial:0, iter:15099/20000 loss:1.7330868744850159\n",
      "generated sequence: We wounht sevles obvest ene instaby of outleatly some of a ped-es, purstac of a\n",
      "     horterss it,\" se\n",
      "\n",
      "rnn_trial:0, iter:15199/20000 loss:1.6765945053100586\n",
      "generated sequence: We had bo mewn he dear surfur was house climes--his fest that I have fertat, as nots,\n",
      "     I tyne, th\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The loss variables.\n",
    "all_losses_rnn = np.zeros(int(iters / print_iters))\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(n_trials):\n",
    "    net_rnn = Net()     # Create a new network instance.\n",
    "    net_rnn.to(device)\n",
    "    opt_rnn       = torch.optim.Adam(net_rnn.parameters(), lr=0.005)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    losses = np.array([])\n",
    "    loss_sum = 0\n",
    "    for j in range(iters):\n",
    "        input, target = get_input_and_target()            # Fetch input and target.\n",
    "        input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "        loss      = train_step(net_rnn, opt_rnn, input, target)   # Calculate the loss.\n",
    "        loss_sum += loss.item()                                  # Accumulate the loss.\n",
    "\n",
    "        # Print the log.\n",
    "        if j % print_iters == print_iters - 1:\n",
    "            print('rnn_trial:{}, iter:{}/{} loss:{}'.format(i, j, iters, loss_sum / print_iters))\n",
    "            print('generated sequence: {}\\n'.format(eval_step(net_rnn)))\n",
    "              \n",
    "            # Track the loss.\n",
    "            losses = np.append(losses, loss_sum / print_iters)\n",
    "            loss_sum = 0\n",
    "    all_losses_rnn += losses\n",
    "    \n",
    "mean_losses_rnn = all_losses_rnn / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses_lstm = np.zeros(int(iters / print_iters))\n",
    "\n",
    "for i in range(n_trials):\n",
    "    net_lstm = Net('LSTM')    # Create a new network instance.\n",
    "    net_lstm.to(device)\n",
    "    opt_lstm      = torch.optim.Adam(net_lstm.parameters(), lr=0.005)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    losses = np.array([])\n",
    "    loss_sum = 0\n",
    "    for j in range(iters):\n",
    "        input, target = get_input_and_target()            # Fetch input and target.\n",
    "        input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "        loss      = train_step(net_lstm, opt_lstm, input, target)   # Calculate the loss.\n",
    "        loss_sum += loss.item()                                  # Accumulate the loss.\n",
    "\n",
    "        # Print the log.\n",
    "        if j % print_iters == print_iters - 1:\n",
    "            print('lstm_trial:{}, iter:{}/{} loss:{}'.format(i, j, iters, loss_sum / print_iters))\n",
    "            print('generated sequence: {}\\n'.format(eval_step(net_lstm)))\n",
    "              \n",
    "            # Track the loss.\n",
    "            losses = np.append(losses, loss_sum / print_iters)\n",
    "            loss_sum = 0\n",
    "    all_losses_lstm += losses\n",
    "\n",
    "mean_losses_lstm = all_losses_lstm / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec259ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Average Loss Over 20,000 Iterations\")\n",
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(mean_losses_rnn)\n",
    "plt.plot(mean_losses_lstm)\n",
    "plt.legend(['RNN', 'LSTM'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33543b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469763c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_step(net_rnn, predicted_len=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315edfdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(eval_step(net_lstm, predicted_len=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Iterations': [1, 5000, 10000, 15000, 20000], \n",
    "     'Standard RNN': [1. ], \n",
    "     'LSTM': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.reset_index().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef074c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.write_html('fig2.html', include_plotlyjs='cdn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
